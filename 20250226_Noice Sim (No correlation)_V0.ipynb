{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Study for Noise Filtering\n",
    "\n",
    "This is the v0 for the simulation study on the sparse jump model comparison with HMM, to show that SJM is able to filter away noisy data by using the weighting in the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from jumpmodels.sparse_jump import SparseJumpModel    # Sparse JM class\n",
    "from jumpmodels.jump import JumpModel    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Simulation & Utility Functions\n",
    "def simulate_data(T, P, mu, random_state=None): \"\"\" Simulate data from a 3-state Gaussian HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(T, P, mu, random_state=None):\n",
    "    \"\"\"\n",
    "    Simulate data from a 3-state Gaussian HMM.\n",
    "    \n",
    "    Parameters:\n",
    "        T (int): Number of observations.\n",
    "        P (int): Total number of features (only first 15 are informative).\n",
    "        mu (float): Signal magnitude for informative features.\n",
    "        random_state (int or None): Seed for reproducibility.\n",
    "        \n",
    "    Returns:\n",
    "        X (ndarray): Simulated observations (T x P).\n",
    "        states (ndarray): True state sequence (length T).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    # Transition matrix as given in your original code\n",
    "    transmat = np.array([[0.9903, 0.0047, 0.0050],\n",
    "                         [0.0157, 0.9666, 0.0177],\n",
    "                         [0.0284, 0.0300, 0.9416]])\n",
    "    transmat = transmat / transmat.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute stationary distribution (eigenvector corresponding to eigenvalue 1)\n",
    "    eigvals, eigvecs = np.linalg.eig(transmat.T)\n",
    "    stat = np.real(eigvecs[:, np.isclose(eigvals, 1)])\n",
    "    stat = stat[:, 0]\n",
    "    stat = stat / np.sum(stat)\n",
    "    \n",
    "    # Generate state sequence\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    states[0] = rng.choice(np.arange(3), p=stat)\n",
    "    for t in range(1, T):\n",
    "        states[t] = rng.choice(np.arange(3), p=transmat[states[t-1]])\n",
    "    \n",
    "    # Define means for each state\n",
    "    means = np.zeros((3, P))\n",
    "    # State 0: +mu in first 15 features\n",
    "    # State 1: 0\n",
    "    # State 2: -mu in first 15 features\n",
    "    if P >= 15:\n",
    "        means[0, :15] = mu\n",
    "        means[2, :15] = -mu\n",
    "    else:\n",
    "        means[0, :P] = mu\n",
    "        means[2, :P] = -mu\n",
    "    \n",
    "    # Generate observations: N(means[state], I_P)\n",
    "    X = np.zeros((T, P))\n",
    "    for t in range(T):\n",
    "        X[t] = rng.normal(loc=means[states[t]], scale=1.0, size=P)\n",
    "    \n",
    "    return X, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Aligning Predicted Labels With True Labels using the Hungarian Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_labels(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Align predicted labels with true labels using the Hungarian algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        aligned (ndarray): Predicted labels after optimal permutation.\n",
    "    \"\"\"\n",
    "    D = confusion_matrix(true_labels, pred_labels)\n",
    "    row_ind, col_ind = linear_sum_assignment(-D)\n",
    "    mapping = {col: row for row, col in zip(row_ind, col_ind)}\n",
    "    aligned = np.array([mapping[x] for x in pred_labels])\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the function to calcuate the BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bac(true_states, pred_states):\n",
    "    \"\"\"\n",
    "    Compute the Balanced Accuracy (BAC) after aligning the predicted state labels.\n",
    "    \"\"\"\n",
    "    aligned_pred = align_labels(true_states, pred_states)\n",
    "    return balanced_accuracy_score(true_states, aligned_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Functions for model formulation\n",
    "\n",
    "### 4.1 HMM With Nystrup (2021) initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hmm(X, n_components=3, random_state=None):\n",
    "    \"\"\"\n",
    "    Fit a Gaussian HMM to the data X with the following initialization:\n",
    "      - Self-transition probability set to 0.95.\n",
    "      - Covariance prior set to 1.0 (for regularization).\n",
    "      - Up to 100 iterations of the EM algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Data matrix.\n",
    "        n_components (int): Number of hidden states.\n",
    "        random_state (int or None): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        pred_states (ndarray): Predicted state sequence using Viterbi decoding.\n",
    "    \"\"\"\n",
    "    model = hmm.GaussianHMM(\n",
    "        n_components=n_components,             # Number of hidden states\n",
    "        covariance_type='diag',                # Diagonal covariance matrices\n",
    "        n_iter=100,                            # Maximum number of EM iterations\n",
    "        random_state=random_state,             # Seed for reproducibility\n",
    "        init_params=\"mc\",                      # Initialize means ('m') and covariances ('c')\n",
    "        covariance_prior=1.0                   # Regularization: prior added to covariance estimates\n",
    "    )\n",
    "    # Set uniform start probabilities\n",
    "    model.startprob_ = np.full(n_components, 1.0 / n_components)\n",
    "    # Initialize transition matrix: 0.95 on the diagonal, the remaining probability spread evenly\n",
    "    transmat = np.full((n_components, n_components), 0.05 / (n_components - 1))\n",
    "    np.fill_diagonal(transmat, 0.95)\n",
    "    model.transmat_ = transmat\n",
    "    \n",
    "    # Fit the model to the data\n",
    "    model.fit(X)\n",
    "    # Predict the hidden state sequence using the Viterbi algorithm\n",
    "    pred_states = model.predict(X)\n",
    "    return pred_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Normal (Standard) Jump Model with Grid Search over Î»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_jump_model_grid_search(X, true_states, n_components=3, random_state=None):\n",
    "    \"\"\"\n",
    "    Perform a grid search over 14 lambda values (logspace from 1e-2 to 1e4) for the jump model.\n",
    "    \n",
    "    For each lambda value:\n",
    "      - A JumpModel is initialized and fitted.\n",
    "      - The jump penalty (lambda) controls the cost of switching states.\n",
    "        - A low lambda allows frequent state changes.\n",
    "        - A high lambda penalizes state changes, resulting in fewer jumps.\n",
    "      - The parameter 'cont' specifies whether the jump model is continuous (True) or discrete (False).\n",
    "      - 'max_iter' defines the maximum number of iterations for the model fitting procedure.\n",
    "    \n",
    "    Parameters:\n",
    "        X (ndarray): Data matrix.\n",
    "        true_states (ndarray): The true hidden state sequence.\n",
    "        n_components (int): Number of states.\n",
    "        random_state (int or None): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        best_labels (ndarray): Predicted state sequence for the best lambda.\n",
    "        best_bac (float): Best balanced accuracy achieved.\n",
    "    \"\"\"\n",
    "    # Create 14 lambda values logarithmically spaced from 0.01 to 10,000.\n",
    "    lambda_values = np.logspace(-2, 4, 14)\n",
    "    best_bac = -1\n",
    "    best_labels = None\n",
    "    \n",
    "    for lam in lambda_values:\n",
    "        # Create a JumpModel instance with the following parameters:\n",
    "        model = JumpModel(\n",
    "            n_components=n_components,    # Number of hidden states\n",
    "            jump_penalty=lam,             # Lambda: penalty for a state transition\n",
    "            cont=False,                   # 'cont': if False, model uses discrete jumps\n",
    "            max_iter=10,                  # Maximum number of iterations for fitting the model\n",
    "            random_state=random_state     # Seed for reproducibility\n",
    "        )\n",
    "        # Fit the jump model to the data X\n",
    "        model.fit(X)\n",
    "        # Retrieve predicted state labels from the model\n",
    "        labels = model.labels_\n",
    "        # Calculate Balanced Accuracy (BAC) after aligning predicted labels with true states\n",
    "        bac = calculate_bac(true_states, labels)\n",
    "        # Update the best result if this lambda gives a higher BAC\n",
    "        if bac > best_bac:\n",
    "            best_bac = bac\n",
    "            best_labels = labels\n",
    "    \n",
    "    return best_labels, best_bac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"orale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running simulation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
